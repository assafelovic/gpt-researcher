"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[30],{5680:(e,t,a)=>{a.d(t,{xA:()=>g,yg:()=>d});var n=a(6540);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),h=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},g=function(e){var t=h(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,g=o(e,["components","mdxType","originalType","parentName"]),p=h(a),u=r,d=p["".concat(l,".").concat(u)]||p[u]||c[u]||i;return a?n.createElement(d,s(s({ref:t},g),{},{components:a})):n.createElement(d,s({ref:t},g))}));function d(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,s=new Array(i);s[0]=u;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[p]="string"==typeof e?e:r,s[1]=o;for(var h=2;h<i;h++)s[h]=a[h];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},7912:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>i,metadata:()=>o,toc:()=>h});var n=a(8168),r=(a(6540),a(5680));const i={slug:"gptr-langgraph",title:"How to Build the Ultimate Research Multi-Agent Assistant",authors:["assafe"],tags:["multi-agents","gpt-researcher","langchain","langgraph"]},s=void 0,o={permalink:"/blog/gptr-langgraph",source:"@site/blog/2024-05-19-gptr-langgraph/index.md",title:"How to Build the Ultimate Research Multi-Agent Assistant",description:"Header",date:"2024-05-19T00:00:00.000Z",formattedDate:"May 19, 2024",tags:[{label:"multi-agents",permalink:"/blog/tags/multi-agents"},{label:"gpt-researcher",permalink:"/blog/tags/gpt-researcher"},{label:"langchain",permalink:"/blog/tags/langchain"},{label:"langgraph",permalink:"/blog/tags/langgraph"}],readingTime:9.76,truncated:!1,authors:[{name:"Assaf Elovic",title:"Creator @ GPT Researcher and Tavily",url:"https://github.com/assafelovic",imageURL:"https://lh3.googleusercontent.com/a/ACg8ocJtrLku69VG_2Y0sJa5mt66gIGNaEBX5r_mgE6CRPEb7A=s96-c",key:"assafe"}],prevItem:{title:"The Future of Research is Hybrid",permalink:"/blog/gptr-hybrid"},nextItem:{title:"How to build an OpenAI Assistant with Internet access",permalink:"/blog/building-openai-assistant"}},l={authorsImageUrls:[void 0]},h=[{value:"Learn how to build an autonomous research assistant using LangGraph with a team of specialized AI agents",id:"learn-how-to-build-an-autonomous-research-assistant-using-langgraph-with-a-team-of-specialized-ai-agents",children:[],level:3},{value:"Introducing LangGraph",id:"introducing-langgraph",children:[],level:2},{value:"Building the Ultimate Autonomous Research Agent",id:"building-the-ultimate-autonomous-research-agent",children:[{value:"The Research Agent Team",id:"the-research-agent-team",children:[],level:3},{value:"Architecture",id:"architecture",children:[],level:3}],level:2},{value:"Define the Graph State",id:"define-the-graph-state",children:[],level:2},{value:"A Graph within a Graph to support stateful Parallelization",id:"a-graph-within-a-graph-to-support-stateful-parallelization",children:[],level:2},{value:"What\u2019s Next?",id:"whats-next",children:[],level:2}],g={toc:h},p="wrapper";function c(e){let{components:t,...i}=e;return(0,r.yg)(p,(0,n.A)({},g,i,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("p",null,(0,r.yg)("img",{alt:"Header",src:a(1197).A})),(0,r.yg)("h1",{id:"introducing-the-gpt-researcher-multi-agent-assistant"},"Introducing the GPT Researcher Multi-Agent Assistant"),(0,r.yg)("h3",{id:"learn-how-to-build-an-autonomous-research-assistant-using-langgraph-with-a-team-of-specialized-ai-agents"},"Learn how to build an autonomous research assistant using LangGraph with a team of specialized AI agents"),(0,r.yg)("p",null,"It has only been a year since the initial release of GPT Researcher, but methods for building, testing, and deploying AI agents have already evolved significantly. That\u2019s just the nature and speed of the current AI progress. What started as simple zero-shot or few-shot prompting, has quickly evolved to agent function calling, RAG and now finally agentic workflows (aka \u201cflow engineering\u201d)."),(0,r.yg)("p",null,"Andrew Ng has ",(0,r.yg)("a",{parentName:"p",href:"https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/"},"recently stated"),", \u201cI think AI agent workflows will drive massive AI progress this year \u2014 perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.\u201d"),(0,r.yg)("p",null,"In this article you will learn why multi-agent workflows are the current best standard and how to build the optimal autonomous research multi-agent assistant using LangGraph."),(0,r.yg)("p",null,"To skip this tutorial, feel free to check out the Github repo of ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/assafelovic/gpt-researcher/tree/master/multi_agents"},"GPT Researcher x LangGraph"),"."),(0,r.yg)("h2",{id:"introducing-langgraph"},"Introducing LangGraph"),(0,r.yg)("p",null,"LangGraph is an extension of LangChain aimed at creating agent and multi-agent flows. It adds in the ability to create cyclical flows and comes with memory built in \u2014 both important attributes for creating agents."),(0,r.yg)("p",null,"LangGraph provides developers with a high degree of controllability and is important for creating custom agents and flows. Nearly all agents in production are customized towards the specific use case they are trying solve. LangGraph gives you the flexibility to create arbitrary customized agents, while providing an intuitive developer experience for doing so."),(0,r.yg)("p",null,"Enough with the smalltalk, let\u2019s start building!"),(0,r.yg)("h2",{id:"building-the-ultimate-autonomous-research-agent"},"Building the Ultimate Autonomous Research Agent"),(0,r.yg)("p",null,"By leveraging LangGraph, the research process can be significantly improved in depth and quality by leveraging multiple agents with specialized skills. Having every agent focus and specialize only a specific skill, allows for better separation of concerns, customizability, and further development at scale as the project grows."),(0,r.yg)("p",null,"Inspired by the recent STORM paper, this example showcases how a team of AI agents can work together to conduct research on a given topic, from planning to publication. This example will also leverage the leading autonomous research agent GPT Researcher."),(0,r.yg)("h3",{id:"the-research-agent-team"},"The Research Agent Team"),(0,r.yg)("p",null,"The research team consists of seven LLM agents:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Chief Editor")," \u2014 Oversees the research process and manages the team. This is the \u201cmaster\u201d agent that coordinates the other agents using LangGraph. This agent acts as the main LangGraph interface."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"GPT Researcher")," \u2014 A specialized autonomous agent that conducts in depth research on a given topic."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Editor")," \u2014 Responsible for planning the research outline and structure."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Reviewer")," \u2014 Validates the correctness of the research results given a set of criteria."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Reviser")," \u2014 Revises the research results based on the feedback from the reviewer."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Writer")," \u2014 Responsible for compiling and writing the final report."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Publisher")," \u2014 Responsible for publishing the final report in various formats.")),(0,r.yg)("h3",{id:"architecture"},"Architecture"),(0,r.yg)("p",null,"As seen below, the automation process is based on the following stages: Planning the research, data collection and analysis, review and revision, writing the report and finally publication:"),(0,r.yg)("p",null,(0,r.yg)("img",{alt:"Architecture",src:a(6643).A})),(0,r.yg)("p",null,"More specifically the process is as follows:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Browser (gpt-researcher)")," \u2014 Browses the internet for initial research based on the given research task. This step is crucial for LLMs to plan the research process based on up to date and relevant information, and not rely solely on pre-trained data for a given task or topic.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Editor")," \u2014 Plans the report outline and structure based on the initial research. The Editor is also responsible for triggering the parallel research tasks based on the planned outline.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},"For each outline topic (in parallel):"),(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Researcher (gpt-researcher)")," \u2014 Runs an in depth research on the subtopics and writes a draft. This agent leverages the GPT Researcher Python package under the hood, for optimized, in depth and factual research report."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Reviewer")," \u2014 Validates the correctness of the draft given a set of guidelines and provides feedback to the reviser (if any)."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Reviser")," \u2014 Revises the draft until it is satisfactory based on the reviewer feedback."))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Writer")," \u2014 Compiles and writes the final report including an introduction, conclusion and references section from the given research findings.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"Publisher")," \u2014 Publishes the final report to multi formats such as PDF, Docx, Markdown, etc.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},"We will not dive into all the code since there\u2019s a lot of it, but focus mostly on the interesting parts I\u2019ve found valuable to share."))),(0,r.yg)("h2",{id:"define-the-graph-state"},"Define the Graph State"),(0,r.yg)("p",null,"One of my favorite features with LangGraph is state management. States in LangGraph are facilitated through a structured approach where developers define a GraphState that encapsulates the entire state of the application. Each node in the graph can modify this state, allowing for dynamic responses based on the evolving context of the interaction."),(0,r.yg)("p",null,"Like in every start of a technical design, considering the data schema throughout the application is key. In this case we\u2019ll define a ResearchState like so:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"class ResearchState(TypedDict):\n    task: dict\n    initial_research: str\n    sections: List[str]\n    research_data: List[dict]\n    # Report layout\n    title: str\n    headers: dict\n    date: str\n    table_of_contents: str\n    introduction: str\n    conclusion: str\n    sources: List[str]\n    report: str\n")),(0,r.yg)("p",null,"As seen above, the state is divided into two main areas: the research task and the report layout content. As data circulates through the graph agents, each agent will, in turn, generate new data based on the existing state and update it for subsequent processing further down the graph with other agents."),(0,r.yg)("p",null,"We can then initialize the graph with the following:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"from langgraph.graph import StateGraph\nworkflow = StateGraph(ResearchState)\n")),(0,r.yg)("p",null,"Initializing the graph with LangGraph\nAs stated above, one of the great things about multi-agent development is building each agent to have specialized and scoped skills. Let\u2019s take an example of the Researcher agent using GPT Researcher python package:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"from gpt_researcher import GPTResearcher\n\nclass ResearchAgent:\n    def __init__(self):\n        pass\n  \n    async def research(self, query: str):\n        # Initialize the researcher\n        researcher = GPTResearcher(parent_query=parent_query, query=query, report_type=research_report, config_path=None)\n        # Conduct research on the given query\n        await researcher.conduct_research()\n        # Write the report\n        report = await researcher.write_report()\n  \n        return report\n")),(0,r.yg)("p",null,"As you can see above, we\u2019ve created an instance of the Research agent. Now let\u2019s assume we\u2019ve done the same for each of the team\u2019s agent. After creating all of the agents, we\u2019d initialize the graph with LangGraph:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def init_research_team(self):\n    # Initialize agents\n    editor_agent = EditorAgent(self.task)\n    research_agent = ResearchAgent()\n    writer_agent = WriterAgent()\n    publisher_agent = PublisherAgent(self.output_dir)\n    \n    # Define a Langchain StateGraph with the ResearchState\n    workflow = StateGraph(ResearchState)\n    \n    # Add nodes for each agent\n    workflow.add_node(\"browser\", research_agent.run_initial_research)\n    workflow.add_node(\"planner\", editor_agent.plan_research)\n    workflow.add_node(\"researcher\", editor_agent.run_parallel_research)\n    workflow.add_node(\"writer\", writer_agent.run)\n    workflow.add_node(\"publisher\", publisher_agent.run)\n    \n    workflow.add_edge('browser', 'planner')\n    workflow.add_edge('planner', 'researcher')\n    workflow.add_edge('researcher', 'writer')\n    workflow.add_edge('writer', 'publisher')\n    \n    # set up start and end nodes\n    workflow.set_entry_point(\"browser\")\n    workflow.add_edge('publisher', END)\n    \n    return workflow\n")),(0,r.yg)("p",null,"As seen above, creating the LangGraph graph is very straight forward and consists of three main functions: add_node, add_edge and set_entry_point. With these main functions you can first add the nodes to the graph, connect the edges and finally set the starting point."),(0,r.yg)("p",null,"Focus check: If you\u2019ve been following the code and architecture properly, you\u2019ll notice that the Reviewer and Reviser agents are missing in the initialization above. Let\u2019s dive into it!"),(0,r.yg)("h2",{id:"a-graph-within-a-graph-to-support-stateful-parallelization"},"A Graph within a Graph to support stateful Parallelization"),(0,r.yg)("p",null,"This was the most exciting part of my experience working with LangGraph! One exciting feature of this autonomous assistant is having a parallel run for each research task, that would be reviewed and revised based on a set of predefined guidelines."),(0,r.yg)("p",null,"Knowing how to leverage parallel work within a process is key for optimizing speed. But how would you trigger parallel agent work if all agents report to the same state? This can cause race conditions and inconsistencies in the final data report. To solve this, you can create a sub graph, that would be triggered from the main LangGraph instance. This sub graph would hold its own state for each parallel run, and that would solve the issues that were raised."),(0,r.yg)("p",null,"As we\u2019ve done before, let\u2019s define the LangGraph state and its agents. Since this sub graph basically reviews and revises a research draft, we\u2019ll define the state with draft information:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"class DraftState(TypedDict):\n    task: dict\n    topic: str\n    draft: dict\n    review: str\n    revision_notes: str\n")),(0,r.yg)("p",null,"As seen in the DraftState, we mostly care about the topic discussed, and the reviewer and revision notes as they communicate between each other to finalize the subtopic research report. To create the circular condition we\u2019ll take advantage of the last important piece of LangGraph which is conditional edges:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'async def run_parallel_research(self, research_state: dict):\n    workflow = StateGraph(DraftState)\n    \n    workflow.add_node("researcher", research_agent.run_depth_research)\n    workflow.add_node("reviewer", reviewer_agent.run)\n    workflow.add_node("reviser", reviser_agent.run)\n    \n    # set up edges researcher->reviewer->reviser->reviewer...\n    workflow.set_entry_point("researcher")\n    workflow.add_edge(\'researcher\', \'reviewer\')\n    workflow.add_edge(\'reviser\', \'reviewer\')\n    workflow.add_conditional_edges(\'reviewer\',\n                                   (lambda draft: "accept" if draft[\'review\'] is None else "revise"),\n                                   {"accept": END, "revise": "reviser"})\n')),(0,r.yg)("p",null,"By defining the conditional edges, the graph would direct to reviser if there exists review notes by the reviewer, or the cycle would end with the final draft. If you go back to the main graph we\u2019ve built, you\u2019ll see that this parallel work is under a node named \u201cresearcher\u201d called by ChiefEditor agent."),(0,r.yg)("p",null,"Running the Research Assistant\nAfter finalizing the agents, states and graphs, it\u2019s time to run our research assistant! To make it easier to customize, the assistant runs with a given task.json file:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "query": "Is AI in a hype cycle?",\n  "max_sections": 3,\n  "publish_formats": {\n    "markdown": true,\n    "pdf": true,\n    "docx": true\n  },\n  "follow_guidelines": false,\n  "model": "gpt-4-turbo",\n  "guidelines": [\n    "The report MUST be written in APA format",\n    "Each sub section MUST include supporting sources using hyperlinks. If none exist, erase the sub section or rewrite it to be a part of the previous section",\n    "The report MUST be written in spanish"\n  ]\n}\n')),(0,r.yg)("p",null,"The task object is pretty self explanatory, however please notice that follow_guidelines if false would cause the graph to ignore the revision step and defined guidelines. Also, the max_sections field defines how many subheaders to research for. Having less will generate a shorter report."),(0,r.yg)("p",null,"Running the assistant will result in a final research report in formats such as Markdown, PDF and Docx."),(0,r.yg)("p",null,"To download and run the example check out the GPT Researcher x LangGraph ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/assafelovic/gpt-researcher/tree/master/multi_agents"},"open source page"),"."),(0,r.yg)("h2",{id:"whats-next"},"What\u2019s Next?"),(0,r.yg)("p",null,"Going forward, there are super exciting things to think about. Human in the loop is key for optimized AI experiences. Having a human help the assistant revise and focus on just the right research plan, topics and outline, would enhance the overall quality and experience. Also generally, aiming for relying on human intervention throughout the AI flow ensures correctness, sense of control and deterministic results. Happy to see that LangGraph already supports this out of the box as seen here."),(0,r.yg)("p",null,"In addition, having support for research about both web and local data would be key for many types of business and personal use cases."),(0,r.yg)("p",null,"Lastly, more efforts can be done to improve the quality of retrieved sources and making sure the final report is built in the optimal storyline."),(0,r.yg)("p",null,"A step forward in LangGraph and multi-agent collaboration in a whole would be where assistants can plan and generate graphs dynamically based on given tasks. This vision would allow assistants to choose only a subset of agents for a given task and plan their strategy based on the graph fundamentals as presented in this article and open a whole new world of possibilities. Given the pace of innovation in the AI space, it won\u2019t be long before a new disruptive version of GPT Researcher is launched. Looking forward to what the future brings!"),(0,r.yg)("p",null,"To keep track of this project\u2019s ongoing progress and updates please join our Discord community. And as always, if you have any feedback or further questions, please comment below!"))}c.isMDXComponent=!0},6643:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/architecture-c650467192975ae0999e5b10ea82a958.jpeg"},1197:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/blog-langgraph-eff5140e985f93f932d5d69baeb86e01.jpeg"}}]);