# MCP Server Environment Configuration
# Copy this file to .env and fill in your values

# Required API Keys
OPENAI_API_KEY=your-openai-api-key-here
TAVILY_API_KEY=your-tavily-api-key-here

# Document Path Configuration
# Path to directory containing documents for analysis
# Default: C:/my_docs (Windows) or ~/my_docs (Linux/Mac)
DOC_PATH=/home/user/my_docs

# OpenAI Configuration (Optional)
OPENAI_BASE_URL=https://api.openai.com/v1

# LLM Model Configuration (Optional)
# Strategic LLM: Used for complex analysis and strategic decisions
STRATEGIC_LLM=gpt-4o

# Smart LLM: Used for standard analysis tasks
SMART_LLM=gpt-4o

# Fast LLM: Used for quick, simple tasks
FAST_LLM=gpt-3.5-turbo

# Server Configuration (Optional)
# Maximum files to process in batch operations
MAX_FILES_DEFAULT=20

# Maximum characters to read per file
MAX_CHARS_PER_FILE=10000

# API timeout in seconds
API_TIMEOUT=60

# Enable debug logging
DEBUG=false
