{
    "groq/distil_whisper_large_v3_en_spec": {
        "litellm_provider": "groq",
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 25,
        "metadata": {
            "notes": "Distilled version of Whisper large-v3, optimized for speed and long-form transcription."
        },
        "mode": "audio_transcription",
        "source": "https://huggingface.co/distil-whisper/distil-large-v3",
        "supports_audio_input": true,
        "supports_prompt_caching": false
    },
    "groq/gemma2_9b_it_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "metadata": {
            "notes": "Instruction-tuned Gemma 2 9B model."
        },
        "mode": "chat",
        "source": "https://huggingface.co/google/gemma-2-9b-it",
        "supports_function_calling": false,
        "supports_prompt_caching": false,
        "supports_system_messages": true,
        "supports_tool_choice": false
    },
    "groq/llama3_70b_8192_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "metadata": {
            "notes": "Llama 3 70B Instruct model."
        },
        "mode": "chat",
        "source": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct",
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "groq/llama3_8b_8192_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "metadata": {
            "notes": "Llama 3 8B Instruct model."
        },
        "mode": "chat",
        "source": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "groq/llama_3_1_8b_instant_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "metadata": {
            "notes": "Llama 3.1 8B instant model, supports long context."
        },
        "mode": "chat",
        "source": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md",
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "groq/llama_3_2_11b_vision_preview_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "metadata": {
            "notes": "Llama 3.2 11B vision preview model."
        },
        "mode": "chat",
        "source": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision",
        "supports_embedding_image_input": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "groq/llama_3_2_1b_preview_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "metadata": {
            "notes": "Llama 3.2 1B preview model."
        },
        "mode": "chat",
        "source": "https://huggingface.co/meta-llama/Llama-3.2-1B",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "groq/llama_3_2_3b_preview_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "metadata": {
            "notes": "Llama 3.2 3B preview model."
        },
        "mode": "chat",
        "source": "https://huggingface.co/meta-llama/Llama-3.2-3B",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "groq/llama_3_2_90b_vision_preview_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "metadata": {
            "notes": "Llama 3.2 90B vision preview model."
        },
        "mode": "chat",
        "source": "https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct",
        "supports_embedding_image_input": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "groq/llama_3_3_70b_specdec_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "metadata": {
            "notes": "Llama 3.3 70B model with speculative decoding."
        },
        "mode": "chat",
        "source": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "groq/llama_3_3_70b_versatile_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "metadata": {
            "notes": "Llama 3.3 70B versatile model, supports long context."
        },
        "mode": "chat",
        "source": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "groq/llama_guard_3_8b_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 8192,
        "metadata": {
            "notes": "Llama Guard 3 8B model for content moderation."
        },
        "mode": "moderation",
        "source": "https://huggingface.co/meta-llama/Llama-Guard-3-8B",
        "supports_prompt_caching": false,
        "supports_system_messages": false
    },
    "groq/mixtral_8x7b_32768_spec": {
        "litellm_provider": "groq",
        "max_input_tokens": 32768,
        "metadata": {
            "notes": "Mixtral 8x7B Instruct model."
        },
        "mode": "chat",
        "source": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
        "supports_function_calling": true,
        "supports_prompt_caching": false,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "groq/whisper_large_v3_spec": {
        "litellm_provider": "groq",
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 25,
        "metadata": {
            "notes": "OpenAI Whisper large-v3 model for audio transcription."
        },
        "mode": "audio_transcription",
        "source": "https://huggingface.co/openai/whisper-large-v3",
        "supports_audio_input": true,
        "supports_prompt_caching": false
    },
    "groq/whisper_large_v3_turbo_spec": {
        "litellm_provider": "groq",
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 25,
        "metadata": {
            "notes": "OpenAI Whisper large-v3-turbo model for audio transcription."
        },
        "mode": "audio_transcription",
        "source": "https://huggingface.co/openai/whisper-large-v3-turbo",
        "supports_audio_input": true,
        "supports_prompt_caching": false
    }
}