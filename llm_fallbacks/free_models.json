{
    "gemini/gemini-exp-1206": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "metadata": {
            "notes": "Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro."
        }
    },
    "gemini-2.0-flash-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash"
    },
    "gemini-2.0-flash-thinking-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash"
    },
    "gemini/gemini-2.0-flash-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "tpm": 4000000,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash"
    },
    "gemini/gemini-2.0-flash-thinking-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "tpm": 4000000,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash"
    },
    "gemini/gemini-1.5-flash-8b": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-flash-8b-exp-0924": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-exp-1114": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "metadata": {
            "notes": "Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro."
        }
    },
    "gemini/gemini-1.5-flash-exp-0827": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-flash-8b-exp-0827": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-pro-exp-0827": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "google/gemini-exp-1206:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "Experimental release (December 6, 2024) of Gemini."
        },
        "litellm_provider": "openrouter"
    },
    "google/gemini-2.0-flash-exp:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](google/gemini-pro-1.5). It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences."
        },
        "supports_function_calling": true,
        "litellm_provider": "openrouter"
    },
    "gemini-pro-experimental": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "input_cost_per_character": 0,
        "output_cost_per_character": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_tool_choice": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental"
    },
    "gemini-flash-experimental": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "input_cost_per_character": 0,
        "output_cost_per_character": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_tool_choice": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental"
    },
    "google/gemini-flash-1.5-8b-exp": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "Gemini Flash 1.5 8B Experimental is an experimental, 8B parameter version of the [Gemini Flash 1.5](/models/google/gemini-flash-1.5) model.\n\nUsage of Gemini is subject to Google's [Gemini Terms of Use](https://ai.google.dev/terms).\n\n#multimodal\n\nNote: This model is currently experimental and not suitable for production use-cases, and may be heavily rate-limited."
        },
        "litellm_provider": "openrouter"
    },
    "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_vision": true,
        "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas"
    },
    "vertex_ai/meta/llama3-405b-instruct-maas": {
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models"
    },
    "vertex_ai/meta/llama3-70b-instruct-maas": {
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models"
    },
    "vertex_ai/meta/llama3-8b-instruct-maas": {
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models"
    },
    "omni-moderation-latest": {
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "mode": "moderation"
    },
    "omni-moderation-latest-intents": {
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "mode": "moderation"
    },
    "omni-moderation-2024-09-26": {
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "mode": "moderation"
    },
    "text-moderation-stable": {
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "mode": "moderations"
    },
    "text-moderation-007": {
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "mode": "moderations"
    },
    "text-moderation-latest": {
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 0,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openai",
        "mode": "moderations"
    },
    "google/gemini-exp-1121:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 40960,
        "max_output_tokens": 8192,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "Experimental release (November 21st, 2024) of Gemini."
        },
        "litellm_provider": "openrouter"
    },
    "google/learnlm-1.5-pro-experimental:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 40960,
        "max_output_tokens": 8192,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "An experimental version of [Gemini 1.5 Pro](/google/gemini-pro-1.5) from Google."
        },
        "litellm_provider": "openrouter"
    },
    "google/gemini-exp-1114:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 40960,
        "max_output_tokens": 8192,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "Gemini 11-14 (2024) experimental model features \"quality\" improvements."
        },
        "litellm_provider": "openrouter"
    },
    "codestral/codestral-latest": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "codestral",
        "mode": "chat",
        "source": "https://docs.mistral.ai/capabilities/code_generation/",
        "supports_assistant_prefill": true
    },
    "codestral/codestral-2405": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "codestral",
        "mode": "chat",
        "source": "https://docs.mistral.ai/capabilities/code_generation/",
        "supports_assistant_prefill": true
    },
    "text-completion-codestral/codestral-latest": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "text-completion-codestral",
        "mode": "completion",
        "source": "https://docs.mistral.ai/capabilities/code_generation/"
    },
    "text-completion-codestral/codestral-2405": {
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "text-completion-codestral",
        "mode": "completion",
        "source": "https://docs.mistral.ai/capabilities/code_generation/"
    },
    "google/gemini-2.0-flash-thinking-exp-1219:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 40000,
        "max_output_tokens": 8000,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "Gemini 2.0 Flash Thinking Mode is an experimental model that's trained to generate the \"thinking process\" the model goes through as part of its response. As a result, Thinking Mode is capable of stronger reasoning capabilities in its responses than the [base Gemini 2.0 Flash model](/google/gemini-2.0-flash-exp)."
        },
        "litellm_provider": "openrouter"
    },
    "mistralai/mistral-7b-instruct:free": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*"
        },
        "mistralai/mistral-7b-instruct:free": {
            "input_cost_per_token": 0.0,
            "output_cost_per_token": 0.0,
            "input_cost_per_image": 0.0,
            "input_cost_per_query": 0.0,
            "max_input_tokens": 8192,
            "max_output_tokens": 4096,
            "metadata": {
                "notes": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*"
            },
            "litellm_provider": "openrouter"
        }
    },
    "meta-llama/llama-3-8b-instruct:free": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/)."
        },
        "meta-llama/llama-3-8b-instruct:free": {
            "input_cost_per_token": 0.0,
            "output_cost_per_token": 0.0,
            "input_cost_per_image": 0.0,
            "input_cost_per_query": 0.0,
            "max_input_tokens": 8192,
            "max_output_tokens": 4096,
            "metadata": {
                "notes": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/)."
            },
            "litellm_provider": "openrouter"
        }
    },
    "openrouter/meta-llama/llama-3-8b-instruct:free": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/)."
        }
    },
    "openrouter/mistralai/mistral-7b-instruct:free": {
        "max_tokens": 8192,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*"
        }
    },
    "meta-llama/llama-3.2-11b-vision-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "Llama 3.2 11B Vision is a multimodal model with 11 billion parameters, designed to handle tasks combining visual and textual data. It excels in tasks such as image captioning and visual question answering, bridging the gap between language generation and visual reasoning. Pre-trained on a massive dataset of image-text pairs, it performs well in complex, high-accuracy image analysis.\n\nIts ability to integrate visual understanding with language processing makes it an ideal solution for industries requiring comprehensive visual-linguistic AI applications, such as content creation, AI-driven customer service, and research.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/)."
        },
        "litellm_provider": "openrouter"
    },
    "meta-llama/llama-3.1-8b-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 8B instruct-tuned version is fast and efficient.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/)."
        },
        "litellm_provider": "openrouter"
    },
    "meta-llama/llama-3.1-70b-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 70B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models in human evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/)."
        },
        "litellm_provider": "openrouter"
    },
    "qwen/qwen-2-7b-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "Qwen2 7B is a transformer-based model that excels in language understanding, multilingual capabilities, coding, mathematics, and reasoning.\n\nIt features SwiGLU activation, attention QKV bias, and group query attention. It is pretrained on extensive data with supervised finetuning and direct preference optimization.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2/) and [GitHub repo](https://github.com/QwenLM/Qwen2).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE)."
        },
        "litellm_provider": "openrouter"
    },
    "google/gemma-2-9b-it:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "Gemma 2 9B by Google is an advanced, open-source language model that sets a new standard for efficiency and performance in its size class.\n\nDesigned for a wide variety of tasks, it empowers developers and researchers to build innovative applications, while maintaining accessibility, safety, and cost-effectiveness.\n\nSee the [launch announcement](https://blog.google/technology/developers/google-gemma-2/) for more details. Usage of Gemma is subject to Google's [Gemma Terms of Use](https://ai.google.dev/gemma/terms)."
        },
        "litellm_provider": "openrouter"
    },
    "microsoft/phi-3-mini-128k-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "Phi-3 Mini is a powerful 3.8B parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. This model is static, trained on an offline dataset with an October 2023 cutoff date."
        },
        "litellm_provider": "openrouter"
    },
    "microsoft/phi-3-medium-128k-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "Phi-3 128K Medium is a powerful 14-billion parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.\n\nAt time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. In the MMLU-Pro eval, the model even comes close to a Llama3 70B level of performance.\n\nFor 4k context length, try [Phi-3 Medium 4K](/models/microsoft/phi-3-medium-4k-instruct)."
        },
        "litellm_provider": "openrouter"
    },
    "openchat/openchat-7b:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "metadata": {
            "notes": "OpenChat 7B is a library of open-source language models, fine-tuned with \"C-RLFT (Conditioned Reinforcement Learning Fine-Tuning)\" - a strategy inspired by offline reinforcement learning. It has been trained on mixed-quality data without preference labels.\n\n- For OpenChat fine-tuned on Mistral 7B, check out [OpenChat 7B](/models/openchat/openchat-7b).\n- For OpenChat fine-tuned on Llama 8B, check out [OpenChat 8B](/models/openchat/openchat-8b).\n\n#open-source"
        },
        "litellm_provider": "openrouter"
    },
    "sagemaker/meta-textgeneration-llama-2-7b": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "mode": "completion"
    },
    "sagemaker/meta-textgeneration-llama-2-7b-f": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "mode": "chat"
    },
    "sagemaker/meta-textgeneration-llama-2-13b": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "mode": "completion"
    },
    "sagemaker/meta-textgeneration-llama-2-13b-f": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "mode": "chat"
    },
    "sagemaker/meta-textgeneration-llama-2-70b": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "mode": "completion"
    },
    "sagemaker/meta-textgeneration-llama-2-70b-b-f": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "sagemaker",
        "mode": "chat"
    },
    "meta-llama/llama-3.1-405b-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 8000,
        "max_output_tokens": 4000,
        "metadata": {
            "notes": "The highly anticipated 400B class of Llama3 is here! Clocking in at 128k context with impressive eval scores, the Meta AI team continues to push the frontier of open-source LLMs.\n\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 405B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models including GPT-4o and Claude 3.5 Sonnet in evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/)."
        },
        "litellm_provider": "openrouter"
    },
    "meta-llama/llama-3.2-3b-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 4096,
        "max_output_tokens": 2048,
        "metadata": {
            "notes": "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/)."
        },
        "litellm_provider": "openrouter"
    },
    "meta-llama/llama-3.2-1b-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 4096,
        "max_output_tokens": 2048,
        "metadata": {
            "notes": "Llama 3.2 1B is a 1-billion-parameter language model focused on efficiently performing natural language tasks, such as summarization, dialogue, and multilingual text analysis. Its smaller size allows it to operate efficiently in low-resource environments while maintaining strong task performance.\n\nSupporting eight core languages and fine-tunable for more, Llama 1.3B is ideal for businesses or developers seeking lightweight yet powerful AI solutions that can operate in diverse multilingual settings without the high computational demand of larger models.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/)."
        },
        "litellm_provider": "openrouter"
    },
    "meta-llama/llama-3.2-90b-vision-instruct:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 4096,
        "max_output_tokens": 2048,
        "mode": "chat",
        "supports_vision": true,
        "metadata": {
            "notes": "The Llama 90B Vision model is a top-tier, 90-billion-parameter multimodal model designed for the most challenging visual reasoning and language tasks. It offers unparalleled accuracy in image captioning, visual question answering, and advanced image-text comprehension. Pre-trained on vast multimodal datasets and fine-tuned with human feedback, the Llama 90B Vision is engineered to handle the most demanding image-based AI tasks.\n\nThis model is perfect for industries requiring cutting-edge multimodal AI capabilities, particularly those dealing with complex, real-time visual and textual analysis.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/)."
        },
        "litellm_provider": "openrouter"
    },
    "undi95/toppy-m-7b:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 4096,
        "max_output_tokens": 2048,
        "metadata": {
            "notes": "A wild 7B parameter model that merges several models using the new task_arithmetic merge method from mergekit.\nList of merged models:\n- NousResearch/Nous-Capybara-7B-V1.9\n- [HuggingFaceH4/zephyr-7b-beta](/models/huggingfaceh4/zephyr-7b-beta)\n- lemonilia/AshhLimaRP-Mistral-7B\n- Vulkane/120-Days-of-Sodom-LoRA-Mistral-7b\n- Undi95/Mistral-pippa-sharegpt-7b-qlora\n\n#merge #uncensored"
        },
        "litellm_provider": "openrouter"
    },
    "huggingfaceh4/zephyr-7b-beta:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 4096,
        "max_output_tokens": 2048,
        "metadata": {
            "notes": "Zephyr is a series of language models that are trained to act as helpful assistants. Zephyr-7B-\u03b2 is the second model in the series, and is a fine-tuned version of [mistralai/Mistral-7B-v0.1](/models/mistralai/mistral-7b-instruct-v0.1) that was trained on a mix of publicly available, synthetic datasets using Direct Preference Optimization (DPO)."
        },
        "litellm_provider": "openrouter"
    },
    "gryphe/mythomax-l2-13b:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 4096,
        "max_output_tokens": 2048,
        "metadata": {
            "notes": "One of the highest performing and most popular fine-tunes of Llama 2 13B, with rich descriptions and roleplay. #merge"
        },
        "litellm_provider": "openrouter"
    },
    "sophosympatheia/rogue-rose-103b-v0.2:free": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "input_cost_per_image": 0.0,
        "input_cost_per_query": 0.0,
        "max_input_tokens": 4096,
        "metadata": {
            "notes": "Rogue Rose demonstrates strong capabilities in roleplaying and storytelling applications, potentially surpassing other models in the 103-120B parameter range. While it occasionally exhibits inconsistencies with scene logic, the overall interaction quality represents an advancement in natural language processing for creative applications.\n\nIt is a 120-layer frankenmerge model combining two custom 70B architectures from November 2023, derived from the [xwin-stellarbright-erp-70b-v2](https://huggingface.co/sophosympatheia/xwin-stellarbright-erp-70b-v2) base.\n"
        },
        "litellm_provider": "openrouter"
    },
    "azure/standard/1024-x-1024/dall-e-2": {
        "input_cost_per_pixel": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure",
        "mode": "image_generation"
    },
    "together_ai/meta-llama/llama-3.3-70b-instruct-turbo-free": {
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "litellm_provider": "together_ai",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "mode": "chat"
    },
    "fireworks-ai-default": {
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "fireworks_ai"
    },
    "1024-x-1024/dall-e-2": {
        "mode": "image_generation",
        "input_cost_per_pixel": 1.9e-08,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "standard/1024-x-1024/dall-e-3": {
        "mode": "image_generation",
        "input_cost_per_pixel": 3.81469e-08,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "azure/standard/1024-x-1024/dall-e-3": {
        "input_cost_per_pixel": 3.81469e-08,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure",
        "mode": "image_generation"
    },
    "standard/1024-x-1792/dall-e-3": {
        "mode": "image_generation",
        "input_cost_per_pixel": 4.359e-08,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "standard/1792-x-1024/dall-e-3": {
        "mode": "image_generation",
        "input_cost_per_pixel": 4.359e-08,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "azure/standard/1024-x-1792/dall-e-3": {
        "input_cost_per_pixel": 4.359e-08,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure",
        "mode": "image_generation"
    },
    "azure/standard/1792-x-1024/dall-e-3": {
        "input_cost_per_pixel": 4.359e-08,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure",
        "mode": "image_generation"
    },
    "hd/1024-x-1792/dall-e-3": {
        "mode": "image_generation",
        "input_cost_per_pixel": 6.539e-08,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "hd/1792-x-1024/dall-e-3": {
        "mode": "image_generation",
        "input_cost_per_pixel": 6.539e-08,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "azure/hd/1024-x-1792/dall-e-3": {
        "input_cost_per_pixel": 6.539e-08,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure",
        "mode": "image_generation"
    },
    "azure/hd/1792-x-1024/dall-e-3": {
        "input_cost_per_pixel": 6.539e-08,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure",
        "mode": "image_generation"
    },
    "512-x-512/dall-e-2": {
        "mode": "image_generation",
        "input_cost_per_pixel": 6.86e-08,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "hd/1024-x-1024/dall-e-3": {
        "mode": "image_generation",
        "input_cost_per_pixel": 7.629e-08,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "azure/hd/1024-x-1024/dall-e-3": {
        "input_cost_per_pixel": 7.629e-08,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure",
        "mode": "image_generation"
    },
    "256-x-256/dall-e-2": {
        "mode": "image_generation",
        "input_cost_per_pixel": 2.4414e-07,
        "output_cost_per_pixel": 0.0,
        "litellm_provider": "openai"
    },
    "azure_ai/cohere-rerank-v3-multilingual": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "input_cost_per_token": 0.0,
        "input_cost_per_query": 0.002,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure_ai",
        "mode": "rerank"
    },
    "azure_ai/cohere-rerank-v3-english": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "input_cost_per_token": 0.0,
        "input_cost_per_query": 0.002,
        "output_cost_per_token": 0.0,
        "litellm_provider": "azure_ai",
        "mode": "rerank"
    },
    "rerank-v3.5": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "input_cost_per_token": 0.0,
        "input_cost_per_query": 0.002,
        "output_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "mode": "rerank"
    },
    "rerank-english-v3.0": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "input_cost_per_token": 0.0,
        "input_cost_per_query": 0.002,
        "output_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "mode": "rerank"
    },
    "rerank-multilingual-v3.0": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "input_cost_per_token": 0.0,
        "input_cost_per_query": 0.002,
        "output_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "mode": "rerank"
    },
    "rerank-english-v2.0": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "input_cost_per_token": 0.0,
        "input_cost_per_query": 0.002,
        "output_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "mode": "rerank"
    },
    "rerank-multilingual-v2.0": {
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_query_tokens": 2048,
        "input_cost_per_token": 0.0,
        "input_cost_per_query": 0.002,
        "output_cost_per_token": 0.0,
        "litellm_provider": "cohere",
        "mode": "rerank"
    },
    "512-x-512/50-steps/stability.stable-diffusion-xl-v0": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.018,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "vertex_ai/imagegeneration@006": {
        "output_cost_per_image": 0.02,
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "vertex_ai/imagen-3.0-fast-generate-001": {
        "output_cost_per_image": 0.02,
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "512-x-512/max-steps/stability.stable-diffusion-xl-v0": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.036,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "max-x-max/50-steps/stability.stable-diffusion-xl-v0": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.036,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.04,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "stability.stable-image-core-v1:0": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.04,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "stability.stable-image-core-v1:1": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.04,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "vertex_ai/imagen-3.0-generate-001": {
        "output_cost_per_image": 0.04,
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "max-x-max/max-steps/stability.stable-diffusion-xl-v0": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.072,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.08,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "stability.sd3-large-v1:0": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.08,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "stability.sd3-5-large-v1:0": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.08,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "stability.stable-image-ultra-v1:0": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.14,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "stability.stable-image-ultra-v1:1": {
        "max_tokens": 77,
        "max_input_tokens": 77,
        "output_cost_per_image": 0.14,
        "litellm_provider": "bedrock",
        "mode": "image_generation"
    },
    "awanllm/Meta-Llama-3-8B-Instruct": {
        "litellm_provider": "awanllm",
        "awanllm/Meta-Llama-3-8B-Instruct": {
            "litellm_provider": "awanllm"
        }
    },
    "awanllm/Meta-Llama-3.1-8B-Instruct": {
        "litellm_provider": "awanllm",
        "awanllm/Meta-Llama-3.1-8B-Instruct": {
            "litellm_provider": "awanllm"
        }
    },
    "awanllm/Awanllm-Llama-3-8B-Dolfin": {
        "litellm_provider": "awanllm",
        "awanllm/Awanllm-Llama-3-8B-Dolfin": {
            "litellm_provider": "awanllm"
        }
    },
    "awanllm/Awanllm-Llama-3-8B-Cumulus": {
        "litellm_provider": "awanllm",
        "awanllm/Awanllm-Llama-3-8B-Cumulus": {
            "litellm_provider": "awanllm"
        }
    },
    "awanllm/Meta-Llama-3-70B-Instruct": {
        "litellm_provider": "awanllm",
        "awanllm/Meta-Llama-3-70B-Instruct": {
            "litellm_provider": "awanllm"
        }
    },
    "awanllm/Meta-Llama-3.1-70B-Instruct": {
        "litellm_provider": "awanllm",
        "awanllm/Meta-Llama-3.1-70B-Instruct": {
            "litellm_provider": "awanllm"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Anubis-v1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Anubis-v1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Cirrus-x1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Cirrus-x1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-CogniLink": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-CogniLink": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Euryale-v2.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Euryale-v2.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Instruct": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Instruct": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Instruct-Abliterated": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Instruct-Abliterated": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Magnum-v4-SE": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Magnum-v4-SE": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Magnum-v4-SE-Cirrus-x1-SLERP": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Magnum-v4-SE-Cirrus-x1-SLERP": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Mhnnn-x1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Mhnnn-x1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Mirai-2.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Mirai-2.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Mirai-3.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Mirai-3.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-MiraiFanfare": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-MiraiFanfare": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-MiraiFanfare-2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-MiraiFanfare-2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-MS-Evalebis": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-MS-Evalebis": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-MS-Evayale": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-MS-Evayale": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-MS-Nevoria": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-MS-Nevoria": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Negative_LLAMA": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Negative_LLAMA": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Negative-Anubis-v1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Negative-Anubis-v1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Nova-Tempus-v0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Nova-Tempus-v0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-ProgressPushDoll-70Bees": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-ProgressPushDoll-70Bees": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Rombos-LLM": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Rombos-LLM": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Sophos-Eva-Euryale-v1.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Sophos-Eva-Euryale-v1.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3-70B-Spellbound-StoryWriter-0.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3-70B-Spellbound-StoryWriter-0.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-ArliAI-RPMax-v1.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-ArliAI-RPMax-v1.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-ArliAI-RPMax-v1.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-ArliAI-RPMax-v1.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Brinebreath": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Brinebreath": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Cakrawala": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Cakrawala": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Celeste-V0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Celeste-V0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Daybreak-storywriter-v0.4": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Daybreak-storywriter-v0.4": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Dracarys2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Dracarys2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Euryale-v2.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Euryale-v2.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-EZO-1.1-it": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-EZO-1.1-it": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Flammades": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Flammades": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-FLDx2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-FLDx2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Ginny": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Ginny": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Glitz-v0.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Glitz-v0.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Gutenberg-Doppel": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Gutenberg-Doppel": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Hanami-x1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Hanami-x1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Hermes-3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Hermes-3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Inori": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Inori": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Lumitron": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Lumitron": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Milasha": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Milasha": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-MS-Astoria-v2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-MS-Astoria-v2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-MythoNemo-v1.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-MythoNemo-v1.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Nautilus-v0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Nautilus-v0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Nemotron-Instruct": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Nemotron-Instruct": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Nemotron-sunfall-v0.7.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Nemotron-sunfall-v0.7.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-New-Dawn-v1.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-New-Dawn-v1.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-NT-Storybreaker-Ministral": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-NT-Storybreaker-Ministral": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-OpenMath2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-OpenMath2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Rombos-LLM-V2.6-Nemotron": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Rombos-LLM-V2.6-Nemotron": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Saoirse": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Saoirse": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-SauerkrautLM": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-SauerkrautLM": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-SoraEToAtetaTegami-3.1X": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-SoraEToAtetaTegami-3.1X": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Spellbound-StoryWriter-0.4": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Spellbound-StoryWriter-0.4": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Sunfall-v0.6.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Sunfall-v0.6.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Tulu-2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-Tulu-2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-WhiteRabbitNeo-2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3.1v3.3)-70B-WhiteRabbitNeo-2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-Arimas-story-RP-V2.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-Arimas-story-RP-V2.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-Athene": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-Athene": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-Hermes-2-Theta-Euryale-Ties-0.8": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-Hermes-2-Theta-Euryale-Ties-0.8": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-New-Dawn-Ultra-v1.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-New-Dawn-Ultra-v1.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-New-Dawn-v1.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-New-Dawn-v1.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-TenyxChat-Daybreak-Storywriter-RAE": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-TenyxChat-Daybreak-Storywriter-RAE": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-TenyxChat-DaybreakStorywriter": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+(3v3.3)-70B-TenyxChat-DaybreakStorywriter": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3-70B-TenyxChat-DaybreakStorywriter": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3-70B-TenyxChat-DaybreakStorywriter": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-ArliAI-RPMax-v1.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-ArliAI-RPMax-v1.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-ArliAI-RPMax-v1.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-ArliAI-RPMax-v1.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-ArliAI-RPMax-v1.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-ArliAI-RPMax-v1.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Brinebreath": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Brinebreath": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Calme-2.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Calme-2.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Celeste-v0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Celeste-v0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Centaur": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Centaur": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Daybreak-Storywriter-v0.4": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Daybreak-Storywriter-v0.4": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Dracarys": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Dracarys": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Dracarys2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Dracarys2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Euryale-v2.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Euryale-v2.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-EZO-1.1-it": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-EZO-1.1-it": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Flammades": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Flammades": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Glitz-v0.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Glitz-v0.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Gutenberg-Doppel": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Gutenberg-Doppel": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Hanami-x1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Hanami-x1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Hermes-3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Hermes-3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Instruct-Abliterated": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Instruct-Abliterated": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Lumitron": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Lumitron": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Mahou-1.5": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Mahou-1.5": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-MS-Astoria-v2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-MS-Astoria-v2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Nautilus-v0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Nautilus-v0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-Instruct": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-Instruct": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-lorablated": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-lorablated": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-Reward": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-Reward": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-Sunfall-v0.7.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-Sunfall-v0.7.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-Tenyxchat-Storybreaker": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Nemotron-Tenyxchat-Storybreaker": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-New-Dawn-v1.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-New-Dawn-v1.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-NT-Storybreaker-Ministral": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-NT-Storybreaker-Ministral": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-OpenMath2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-OpenMath2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-PlumChat": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-PlumChat": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Rombos-LLM-V2.6-Nemotron": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Rombos-LLM-V2.6-Nemotron": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Saoirse": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Saoirse": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-SauerkrautLM": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-SauerkrautLM": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-ShiningValiant2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-ShiningValiant2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Sunfall-v0.6.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Sunfall-v0.6.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Swallow-v0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Swallow-v0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-TenyxChat-DaybreakStorywriter": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-TenyxChat-DaybreakStorywriter": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Tess-3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Tess-3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Tess-R1-Limerick": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Tess-R1-Limerick": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-Tulu-2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-Tulu-2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.3+3.1-70B-WhiteRabbitNeo-2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.3+3.1-70B-WhiteRabbitNeo-2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.33-70B-EVA-v0.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.33-70B-EVA-v0.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Llama-3.33-70B-EVA-v0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Llama-3.33-70B-EVA-v0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-ArliAI-RPMax-v1.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-ArliAI-RPMax-v1.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-ArliAI-RPMax-v1.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-ArliAI-RPMax-v1.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-ArliAI-RPMax-v1.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-ArliAI-RPMax-v1.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-BackyardAI-Party-v1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-BackyardAI-Party-v1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-BD-RP": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-BD-RP": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-CelesteGold": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-CelesteGold": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Chinofun-2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Chinofun-2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Chunky-Lotus": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Chunky-Lotus": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Dark-Planet-TITAN": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Dark-Planet-TITAN": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Estrella-v2.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Estrella-v2.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Fireball-Philos": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Fireball-Philos": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Guns-And-Roses-R1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Guns-And-Roses-R1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Halide-v1.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Halide-v1.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Himeyuri-v0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Himeyuri-v0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Inferor-v0.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Inferor-v0.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Lyra-v4": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Lyra-v4": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Mag-Mell-R1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Mag-Mell-R1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Maghin": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Maghin": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Magnum-v4": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Magnum-v4": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Mahou-1.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Mahou-1.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Mahou-1.5": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Mahou-1.5": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-NemoMix-Unleashed": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-NemoMix-Unleashed": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Nemomix-v4.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Nemomix-v4.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-NemoRemix": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-NemoRemix": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Pantheon-RP-1.6": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Pantheon-RP-1.6": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Pantheon-RP-1.6-KTO": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Pantheon-RP-1.6-KTO": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Pantheon-RP-1.6.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Pantheon-RP-1.6.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Picaro-0.7-Magnum-v2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Picaro-0.7-Magnum-v2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Prismatic": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Prismatic": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Rocinante-v1.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Rocinante-v1.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Rosier-v1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Rosier-v1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-RP-Ink": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-RP-Ink": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-SauerkrautLM": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-SauerkrautLM": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Siskin-v0.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Siskin-v0.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Slush": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Slush": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Starcannon-Unleashed-v1.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Starcannon-Unleashed-v1.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Stellar-Odyssey-v0.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Stellar-Odyssey-v0.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Sunfall": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Sunfall": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Sunrose": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Sunrose": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Tarsus": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Tarsus": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Tiramisu": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Tiramisu": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-UnslopNemo-v4": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-UnslopNemo-v4": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-UnslopNemo-v4.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-UnslopNemo-v4.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Vespa-x1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Vespa-x1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Violet-Lotus": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Violet-Lotus": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Mistral-Nemo-12B-Wayfarer": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Mistral-Nemo-12B-Wayfarer": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-AGI": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-AGI": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-ArliAI-Ink-RPMaxxed-v1.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-ArliAI-Ink-RPMaxxed-v1.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-ArliAI-Ink-RPMaxxed-v1.0-ep0.5": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-ArliAI-Ink-RPMaxxed-v1.0-ep0.5": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-ArliAI-RPMax-v1.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-ArliAI-RPMax-v1.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Awqward2.5": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Awqward2.5": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Dazzling-Star-Aurora-32b-v0.0": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Dazzling-Star-Aurora-32b-v0.0": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-EVA-Gutenberg-Doppel": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-EVA-Gutenberg-Doppel": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-EVA-v0.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-EVA-v0.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-EZO": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-EZO": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-EZO-AutoCoTRAG": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-EZO-AutoCoTRAG": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Gutenberg-Doppel": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Gutenberg-Doppel": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Instruct": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Instruct": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Instruct-abliterated": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Instruct-abliterated": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Kunou-v1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Kunou-v1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Peganum-v0.1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Peganum-v0.1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Qwentile": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Qwentile": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-QwQ-Preview": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-QwQ-Preview": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-Rombos-LLM-V2.5": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-Rombos-LLM-V2.5": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-32B-RP-Ink": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-32B-RP-Ink": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Athene-V2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Athene-V2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Chronos-Platinum": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Chronos-Platinum": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Chuluun-v0.01": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Chuluun-v0.01": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Chuluun-v0.08": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Chuluun-v0.08": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Chuluun-v0.08-128r": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Chuluun-v0.08-128r": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-EurobeatVARemix": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-EurobeatVARemix": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-EVA-v0.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-EVA-v0.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-EVA-v0.2-128r": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-EVA-v0.2-128r": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Evathene-v1.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Evathene-v1.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Evathene-v1.3": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Evathene-v1.3": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Instruct": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Instruct": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Kunou-v1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Kunou-v1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-MachiNoDolphin": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-MachiNoDolphin": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-Magnum-v4": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-Magnum-v4": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-MS-Mistoria": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-MS-Mistoria": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-MS-Mistoria-v2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-MS-Mistoria-v2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-RP-Ink": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-RP-Ink": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-RP-Ink-Experimental-ep1": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-RP-Ink-Experimental-ep1": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/(TRIAL) Qwen2.5-72B-SteyrCannon-0.2": {
        "litellm_provider": "arliai",
        "arliai/(TRIAL) Qwen2.5-72B-SteyrCannon-0.2": {
            "litellm_provider": "arliai"
        }
    },
    "arliai/Mistral-Nemo-12B-Instruct-2407": {
        "litellm_provider": "arliai",
        "arliai/Mistral-Nemo-12B-Instruct-2407": {
            "litellm_provider": "arliai"
        }
    },
    "groq/whisper-large-v3-turbo": {
        "litellm_provider": "groq"
    },
    "groq/llama-guard-3-8b": {
        "litellm_provider": "groq"
    },
    "groq/whisper-large-v3": {
        "litellm_provider": "groq"
    },
    "groq/distil-whisper-large-v3-en": {
        "litellm_provider": "groq"
    },
    "together_ai/mistralai/mistral-7b-instruct-v0.1": {
        "litellm_provider": "together_ai",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "mode": "chat"
    },
    "together_ai/togethercomputer/codellama-34b-instruct": {
        "litellm_provider": "together_ai",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "mode": "chat"
    },
    "awanllm/meta-llama-3-8b-instruct": {
        "litellm_provider": "awanllm"
    },
    "awanllm/meta-llama-3.1-8b-instruct": {
        "litellm_provider": "awanllm"
    },
    "awanllm/awanllm-llama-3-8b-dolfin": {
        "litellm_provider": "awanllm"
    },
    "awanllm/awanllm-llama-3-8b-cumulus": {
        "litellm_provider": "awanllm"
    },
    "awanllm/meta-llama-3-70b-instruct": {
        "litellm_provider": "awanllm"
    },
    "awanllm/meta-llama-3.1-70b-instruct": {
        "litellm_provider": "awanllm"
    },
    "arliai/(trial) llama-3.3-70b-anubis-v1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-cirrus-x1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-cognilink": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-euryale-v2.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-instruct": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-instruct-abliterated": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-magnum-v4-se": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-magnum-v4-se-cirrus-x1-slerp": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-mhnnn-x1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-mirai-2.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-mirai-3.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-miraifanfare": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-miraifanfare-2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-ms-evalebis": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-ms-evayale": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-ms-nevoria": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-negative_llama": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-negative-anubis-v1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-nova-tempus-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-progresspushdoll-70bees": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-rombos-llm": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-sophos-eva-euryale-v1.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3-70b-spellbound-storywriter-0.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-arliai-rpmax-v1.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-arliai-rpmax-v1.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-brinebreath": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-cakrawala": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-celeste-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-daybreak-storywriter-v0.4": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-dracarys2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-euryale-v2.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-ezo-1.1-it": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-flammades": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-fldx2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-ginny": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-glitz-v0.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-gutenberg-doppel": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-hanami-x1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-hermes-3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-inori": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-lumitron": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-milasha": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-ms-astoria-v2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-mythonemo-v1.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-nautilus-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-nemotron-instruct": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-nemotron-sunfall-v0.7.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-new-dawn-v1.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-nt-storybreaker-ministral": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-openmath2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-rombos-llm-v2.6-nemotron": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-saoirse": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-sauerkrautlm": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-soraetoatetategami-3.1x": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-spellbound-storywriter-0.4": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-sunfall-v0.6.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-tulu-2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3.1v3.3)-70b-whiterabbitneo-2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3v3.3)-70b-arimas-story-rp-v2.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3v3.3)-70b-athene": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3v3.3)-70b-hermes-2-theta-euryale-ties-0.8": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3v3.3)-70b-new-dawn-ultra-v1.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3v3.3)-70b-new-dawn-v1.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3v3.3)-70b-tenyxchat-daybreak-storywriter-rae": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+(3v3.3)-70b-tenyxchat-daybreakstorywriter": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3-70b-tenyxchat-daybreakstorywriter": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-arliai-rpmax-v1.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-arliai-rpmax-v1.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-arliai-rpmax-v1.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-brinebreath": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-calme-2.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-celeste-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-centaur": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-daybreak-storywriter-v0.4": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-dracarys": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-dracarys2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-euryale-v2.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-ezo-1.1-it": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-flammades": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-glitz-v0.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-gutenberg-doppel": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-hanami-x1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-hermes-3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-instruct-abliterated": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-lumitron": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-mahou-1.5": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-ms-astoria-v2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-nautilus-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-nemotron-instruct": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-nemotron-lorablated": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-nemotron-reward": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-nemotron-sunfall-v0.7.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-nemotron-tenyxchat-storybreaker": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-new-dawn-v1.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-nt-storybreaker-ministral": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-openmath2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-plumchat": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-rombos-llm-v2.6-nemotron": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-saoirse": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-sauerkrautlm": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-shiningvaliant2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-sunfall-v0.6.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-swallow-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-tenyxchat-daybreakstorywriter": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-tess-3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-tess-r1-limerick": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-tulu-2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.3+3.1-70b-whiterabbitneo-2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.33-70b-eva-v0.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) llama-3.33-70b-eva-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-arliai-rpmax-v1.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-arliai-rpmax-v1.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-arliai-rpmax-v1.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-backyardai-party-v1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-bd-rp": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-celestegold": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-chinofun-2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-chunky-lotus": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-dark-planet-titan": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-estrella-v2.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-fireball-philos": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-guns-and-roses-r1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-halide-v1.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-himeyuri-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-inferor-v0.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-lyra-v4": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-mag-mell-r1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-maghin": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-magnum-v4": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-mahou-1.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-mahou-1.5": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-nemomix-unleashed": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-nemomix-v4.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-nemoremix": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-pantheon-rp-1.6": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-pantheon-rp-1.6-kto": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-pantheon-rp-1.6.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-picaro-0.7-magnum-v2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-prismatic": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-rocinante-v1.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-rosier-v1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-rp-ink": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-sauerkrautlm": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-siskin-v0.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-slush": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-starcannon-unleashed-v1.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-stellar-odyssey-v0.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-sunfall": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-sunrose": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-tarsus": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-tiramisu": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-unslopnemo-v4": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-unslopnemo-v4.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-vespa-x1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-violet-lotus": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) mistral-nemo-12b-wayfarer": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-agi": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-arliai-ink-rpmaxxed-v1.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-arliai-ink-rpmaxxed-v1.0-ep0.5": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-arliai-rpmax-v1.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-awqward2.5": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-dazzling-star-aurora-32b-v0.0": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-eva-gutenberg-doppel": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-eva-v0.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-ezo": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-ezo-autocotrag": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-gutenberg-doppel": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-instruct": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-instruct-abliterated": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-kunou-v1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-peganum-v0.1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-qwentile": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-qwq-preview": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-rombos-llm-v2.5": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-32b-rp-ink": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-athene-v2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-chronos-platinum": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-chuluun-v0.01": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-chuluun-v0.08": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-chuluun-v0.08-128r": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-eurobeatvaremix": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-eva-v0.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-eva-v0.2-128r": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-evathene-v1.2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-evathene-v1.3": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-instruct": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-kunou-v1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-machinodolphin": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-magnum-v4": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-ms-mistoria": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-ms-mistoria-v2": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-rp-ink": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-rp-ink-experimental-ep1": {
        "litellm_provider": "arliai"
    },
    "arliai/(trial) qwen2.5-72b-steyrcannon-0.2": {
        "litellm_provider": "arliai"
    },
    "arliai/mistral-nemo-12b-instruct-2407": {
        "litellm_provider": "arliai"
    }
}